{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8961722,"sourceType":"datasetVersion","datasetId":5118454},{"sourceId":9098705,"sourceType":"datasetVersion","datasetId":5299006},{"sourceId":9132584,"sourceType":"datasetVersion","datasetId":5318438}],"dockerImageVersionId":30158,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"See original StyleGAN2 ADA github repo here: https://github.com/NVlabs/stylegan2-ada-pytorch\n\nBy using a pre-trained model along with data heavy data augmentation, we can train our own GAN with a very limited dataset (<1000 images). ","metadata":{}},{"cell_type":"code","source":"!pip install pillow\n!pip install pyspng ninja imageio-ffmpeg==0.4.3\n!git clone https://github.com/PDillis/stylegan3-fun\n!pip install gdown\n!pip install torch==1.11.0\n%cd ./stylegan3-fun","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:31:09.101104Z","iopub.execute_input":"2024-08-09T11:31:09.101448Z","iopub.status.idle":"2024-08-09T11:32:57.194700Z","shell.execute_reply.started":"2024-08-09T11:31:09.101360Z","shell.execute_reply":"2024-08-09T11:32:57.193588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Read CSV files\ntrain_csv = pd.read_csv(\"/kaggle/input/fetalhcdata/training_set/training_set_circumference.csv\")\ntrain_img = \"/kaggle/input/fetalhcdata/training_set/training_set\"\ntest_csv = pd.read_csv(\"/kaggle/input/fetalhcdata/test_set/test_set_circumference.csv\")\ntest_img = \"/kaggle/input/fetalhcdata/test_set/test_set\"\n\ndef resize_images(image_ps, save_dir, size=(512, 512)):\n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n    \n    # Counter for image naming\n    image_count = 0\n    \n    for image_path in image_ps:\n        try:\n            with Image.open(image_path) as img:\n                img = img.resize(size, Image.LANCZOS)\n                \n                # Convert to RGB if image is in RGBA mode\n                if img.mode == 'RGBA':\n                    img = img.convert('RGB')\n                \n                # Create new filename\n                new_file_name = f\"image_{image_count}.jpg\"\n                output_path = os.path.join(save_dir, new_file_name)\n                img.save(output_path)\n                \n                # Increment the image counter\n                image_count += 1\n        except Exception as e:\n            print(f\"Error processing {image_path}: {e}\")\n\n# Generate paths for the filtered data\ntrain_paths = [os.path.join(train_img, filename) for filename in train_csv['filename']]\ntest_paths = [os.path.join(test_img, filename) for filename in test_csv['filename']]\n\n# Combine the paths and resize images\noutput_directory = 'new_imgs'\nresize_images(train_paths + test_paths, output_directory)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:32:57.197170Z","iopub.execute_input":"2024-08-09T11:32:57.197430Z","iopub.status.idle":"2024-08-09T11:33:32.934260Z","shell.execute_reply.started":"2024-08-09T11:32:57.197398Z","shell.execute_reply":"2024-08-09T11:33:32.933593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python dataset_tool.py --source=./new_imgs --dest=./datasets/FH.zip","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:33:32.935375Z","iopub.execute_input":"2024-08-09T11:33:32.935644Z","iopub.status.idle":"2024-08-09T11:34:02.903099Z","shell.execute_reply.started":"2024-08-09T11:33:32.935595Z","shell.execute_reply":"2024-08-09T11:34:02.902315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py --help","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:18:01.760548Z","iopub.execute_input":"2024-08-07T06:18:01.760791Z","iopub.status.idle":"2024-08-07T06:18:05.555685Z","shell.execute_reply.started":"2024-08-07T06:18:01.760759Z","shell.execute_reply":"2024-08-07T06:18:05.554869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py --outdir=./results --snap=5 --img-snap=5 --cfg=stylegan2 --data=./datasets/FH.zip --resume=afhqwild512 --augpipe=noise --gpus=2 --metrics=None --gamma=36 --batch=8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate Synthetic Images\n#### The code below is for RGB","metadata":{}},{"cell_type":"code","source":"!pip install moviepy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outdir = './results'\nos.makedirs(outdir, exist_ok=True)\n!python generate.py images --outdir=outdir --trunc=1 --seeds=0-9 --network=/kaggle/working/stylegan3-fun/results/00000-stylegan2-FH-gpus2-batch8-gamma8-resume_custom/network-snapshot-000100.pkl","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\n\n# Paths\ninput_dir = './results/00000-generate-images'\noutput_dir = './results/generated_grayscale'\n\n# Create output directory if it does not exist\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n# Process each image\nfor filename in os.listdir(input_dir):\n    # Build the path to the input file\n    input_path = os.path.join(input_dir, filename)\n    \n    # Check if it's an image file\n    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n        # Read the image\n        image = cv2.imread(input_path)\n        \n        # Convert to grayscale\n        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        \n        # Build the path to the output file\n        output_path = os.path.join(output_dir, filename)\n        \n        # Save the grayscale image\n        cv2.imwrite(output_path, gray_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python dataset_tool.py --source=./results/generated_grayscale --dest=./results/gan_images.zip","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The code below is for gray images","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport PIL.Image\nimport dnnlib\nimport legacy\n\ndef generate_images(network_pkl, seeds, truncation_psi, outdir):\n    device = torch.device('cuda')\n    \n    # Load the pre-trained network\n    with dnnlib.util.open_url(network_pkl) as f:\n        G = legacy.load_network_pkl(f)['G_ema'].to(device)  # type: ignore\n\n    os.makedirs(outdir, exist_ok=True)\n\n    for seed in seeds:\n        # Generate latent vectors\n        z = torch.from_numpy(np.random.RandomState(seed).randn(1, G.z_dim)).to(device)\n        img = G(z, None, truncation_psi=truncation_psi, noise_mode='const')\n\n        # Convert the generated image to a format that can be saved\n        img = (img * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n        img = img.permute(0, 2, 3, 1)  # [1, h, w, c]\n        \n        # Convert to numpy and save as grayscale image\n        img_np = img[0].cpu().numpy().squeeze()  # [h, w]\n        PIL.Image.fromarray(img_np, 'L').save(f'{outdir}/seed{seed:04d}.png')\n\n# Example usage\nnetwork_pkl = '/kaggle/working/stylegan2-ada-pytorch/results/00000-fetalH-paper512-blit-resumecustom/network-snapshot-000080.pkl'\nseeds = range(0, 1000)\ntruncation_psi = 1\noutdir = './results/generated'\n\ngenerate_images(network_pkl, seeds, truncation_psi, outdir)\nprint('Images Generated Successfully')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python dataset_tool.py --source=./results/generated --dest=./results/gan_images.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}